---
title: "England Peat Depth Model: Train models"
output: html_notebook
---

#Peat Depths: run models

## Packages 
```{r, include=FALSE}
library(raster)
library(rgdal)

library(randomForest)
library(Rborist)

library(caret)
library(parallel)
library(doParallel)
```

## Load data
```{r}
load(file = "../data/input.data.rds")
dim(input.data)
```


## Start Parallel Processing
```{r}
detectCores()
getDoParWorkers()
cl <- makeCluster(detectCores()-1)
registerDoParallel(cl)
getDoParName()
getDoParWorkers()
#registerDoSEQ() # to stop parallel processing
```


## Make training and test sets

```{r}
set.seed(123)
inTrain <- createDataPartition(y = input.data$PEAT_DEPTH, 
                               p = .75, # The percentage of data in the training set
                               list = FALSE) # The format of the results

training <- input.data[inTrain,]
testing <- input.data[-inTrain,]
```
Training data has `r nrow(training)` records.  Testing data has `r nrow(testing)` records.  

#### train model
Need the latest version of caret from github to avoid known bug.

set model parameters
```{r}
params <- trainControl(method = "cv", number = 10)
```

train linear model
```{r}
Mlm2a <- train(PEAT_DEPTH ~ ., 
              data = training, 
              method = "lm")

save(Mlm2a, file = "../data/models/Mlm2a.rds")

Mlm2a
```

train random forest model
```{r}
Mrf2a <- train(PEAT_DEPTH ~ ., 
              data = training, 
              method = "Rborist")

save(Mrf2a, file = "../data/models/Mrf2a.rds")

Mrf2a
```


```{r}
rbind(getTrainPerf(Mlm2a), getTrainPerf(Mrf2a))
```

train generalised linear model
```{r}
Mglm2a <- train(PEAT_DEPTH ~ ., 
              data = training, 
              method = "glm")

save(Mglm2a, file = "../data/models/Mglm2a.rds")

Mglm2a
```

train boosted generalised linear model
```{r}
Mbglm2a <- train(PEAT_DEPTH ~ ., 
              data = training, 
              method = "glmboost")

save(Mbglm2a, file = "../data/models/Mbglm2a.rds")

Mbglm2a
```

train k nearest neighbours model

```{r}
Mknn2a <- train(PEAT_DEPTH ~ ., 
              data = training, 
              method = "knn")

save(Mknn2a, file = "../data/models/Mknn2a.rds")

Mknn2a
```


train Generalised Additive Model 

```{r}
Mgam2a <- train(PEAT_DEPTH ~ ., 
              data = training, 
              method = "gam")

save(Mgam2a, file = "../data/models/Mgam2a.rds")

Mgam2a
```

train Gradient Boosting Model 

```{r}
Mgbm2a <- train(PEAT_DEPTH ~ ., 
              data = training, 
              method = "gbm")

save(Mgbm2a, file = "../data/models/Mgbm2a.rds")

Mgbm2a
```



## Evaluate models



```{r}
cvValues <- resamples(list(LM = Mlm2a, RF = Mrf2a, GLM = Mglm2a, GLMB = Mbglm2a, 
                           GAM = Mgam2a, GBM = Mgbm2a))
summary(cvValues)
splom(cvValues, metric = "Rsquared")
parallelplot(cvValues, metric = "Rsquared")
dotplot(cvValues, metric = "Rsquared")
```

```{r}
Diffs <- diff(cvValues, metric = "Rsquared")
summary(Diffs)
dotplot(Diffs, metric = "Rsquared")
```

## predict test data from model and evaluate

```{r}
lm_pred <- predict(Mlm2a, training)

rf_pred <- predict(Mrf2a, training)

glm_pred <- predict(Mglm2a, training)

glmb_pred <- predict(Mbglm2a, training) 

gam_pred <- predict(Mgam2a, training)

gbm_pred <- predict(Mgbm2a, training)

```

Calculate deviation

**RMSE**: Root Mean Square Error. Standard deviation of the differences between predicted and observed values.  Measures accuracy.  Scale-dependent, so can't compare different datasets.  Sensitive to outliers. Smaller is better.  Calculated by   `sqrt(mean((pred - obs)^2` 

**Rsquared**: Coefficient of determination.  The proportion of the variation in the observed variable that is predictable from the predicted variable.  Not scale dependent.  Closer to 1 is better. Calculated by `R^2 = 1-\frac{∑ (y_i - \hat{y}_i)^2}{∑ (y_i - \bar{y}_i)^2}`

**MAE**: Mean Absolute Error.  The average of the difference between the absolute predicted and observed values.  Scale-dependent, so can't compare different datasets.  Sensitive to outliers. Smaller is better.  Calculated by `mean(abs(pred - obs))`


```{r}
mod_variance <- data.frame(rbind(
  postResample(pred = lm_pred, obs = training$PEAT_DEPTH),
  postResample(pred = rf_pred, obs = training$PEAT_DEPTH),
  postResample(pred = glm_pred, obs = training$PEAT_DEPTH),
  postResample(pred = glmb_pred, obs = training$PEAT_DEPTH),
  postResample(pred = gam_pred, obs = training$PEAT_DEPTH),
  postResample(pred = gbm_pred, obs = training$PEAT_DEPTH)
))

mod_variance <- cbind(model = c("lm", "rf", "glm", "glmb", "gam", "gbm"), mod_variance)
mod_variance
```

## Train full models

```{r}
Mlm2a.full <- train(PEAT_DEPTH ~ ., 
              data = input.data, 
              method = "lm")

save(Mlm2a.full, file = "../data/models/Mlm2a.full.rds")

Mlm2a.full
```

train model
```{r}
Mrf2a.full <- train(PEAT_DEPTH ~ ., 
              data = input.data, 
              method = "Rborist")

save(Mrf2a.full, file = "../data/models/Mrf2a.full.rds")

Mrf2a.full
```

evaluate
```{r}
rbind(getTrainPerf(Mlm2a.full), getTrainPerf(Mrf2a.full))
```

